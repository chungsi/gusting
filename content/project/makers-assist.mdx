---
title: Maker's Assist
subtitle: an accessibility app design for the mobility impaired
hero_image: './../assets/puff.png'
hero_image_pos: top

category: design
tags:
  - user experience
  - interface design

publish: true
feature: true
---

**timeline**: 2.5 months  
**team size**: five people

## My Roles

Visual design, illustration, and UI
UX: User research, interviewing our audiences, user testing
Videography: Camera, editing, sound design


## Pitch

For the Makers Assist App, we partnered with the Neil Squire Society to help them design a UI/UX for their newly created LipSync device, which helps quadriplegics navigate their mobile devices with the control of their mouth only. However, the LipSync could not press hardware buttons nor perform complex finger gestures (ie. swiping). So together with the Neil Squire Society, we determined that the best solution is a UI overlay that would convert these issues into simple click buttons.

The goal was to create an effective user experience that could make mobile devices as easy to use for quadriplegics as they are for any able-bodied person. Through the process of user research, idea proposal, and user testing, we created the final UI overlay design that is most intuitive for quadriplegics.

Below is the final concept pitch video.

<iframe title="vimeo-player" src="https://player.vimeo.com/video/211353188" width="656" height="375" frameborder="0" allowfullscreen></iframe>


## Process

### Research

The first step after meeting with Neil Squire Society was to conduct user research. This meant looking at solutions made by competing companies and meeting with users to learn about their habits and routines. In particular, we interviewed people with limited or no hand use at a LipSync workshop, pictured below.

[insert picture]

We created a journey map after collecting our research to further analyse the process and pain points of three seemingly trivial tasks to the physically able: 

* typing and scrolling while using Google Search;  
* swiping to answer a phone call; and  
* pinch-zooming and scrolling while using Google Maps.  

We found that these tasks are indeed extremely difficult for those with motor disabilities, and aimed our proposals to address them.

[insert picture]


### Proposals

Our research showed that users wanted to modify the environment to their own needs. After a process of ideation, we decided on a two-level menu system that combined two sketch proposals to reduce movement-distance with the mouse. A circle-overlay opens into a menu of hardware tasks while a quick-access shelf at the bottom of the screen has frequently used apps or actions. User customization would be added in the initial design.

Below are the initial sketches we built-off of and refined to create our first prototype.

[insert pictures]


### Initial Design, Testing, & Struggles

During the initial design of the UI overlay, we created a fully interactive axure mockup to simulate the mobile devices we were using. This mockup was embedded into an android application so that users could test the LipSync with the mockup.

Quadriplegics then tested our mockup with their own LipSync device. It was here where we discovered the inherent problems with the LipSync, and the challenges in designing for a device that is still in development. While we didn't receive the feedback we expected, we did find that users struggled to understand how the LipSync worked. This gave us an opportunity to embed this information into the UI, and hopefully have users understand the LipSync before they incorporate it to their mobile device.

[insert image]


## Final Design

We compiled our final concept pitch in a video, explaining the features we designed and the scenarios we explored in our journey map. Below is an overview of the features explained.

The onboarding to LipSync and our Maker's Assist application was heavily influenced by our user testing. Users learn about the modes that include the actions of: swiping, drag & drop, scroll, zoom, and screenshot.

[images]

Example interactions of the Maker's Assist app below show swiping and zooming, which make use of the bottom quick menu for actions and the circle-overlap to remind users what interaction mode they are currently in.

[images]

Users can set their custom actions for either menu easily:

[images]


## Reflections

Ultimately, our concentration was not on building features into the application. Rather, we worked to streamline the onboarding and customization of the UI and the LipSync device. With the focus on user experience, we were able to learn a lot about understanding the users while working with clients. This made the implementation of the system easy for the developer at NSS, so that he could concentrate on the code rather than the process of the project.